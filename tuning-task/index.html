<html>
  <head>
    <title>ACL 2016 First Conference  on  Machine Translation (WMT16)</title>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <style> h3 { margin-top: 2em; } </style>
  </head>
  <body>

    <center>
      <script src="http://www.statmt.org/wmt16/title.js"></script>
      <p><h2>WMT16 Tuning Task</h2></p>
      <script src="http://www.statmt.org/wmt16/menu.js"></script>
    </center>

    <h3>Tuning Task Important Dates</h3>

    <table>
      <tr><td>Release of the MT system to tune</td><td><strike>February</strike>March 30, 2016</td></tr>
      <tr><td>Submission deadline for tuning task</td><td><strike>April 17</strike> <b>April 24, 2016</b></td></tr>
      <tr><td>Start of manual evaluation period</td><td>May 2, 2016</td></tr>
      <tr><td>Paper submission deadline</td><td>May 8, 2016</td></tr>
      <tr><td>End of manual evaluation</td><td>May 22, 2016</td></tr>
      <tr><td>Notification of acceptance</td><td>June 5, 2016</td></tr>
      <tr><td>Camera-ready deadline</td><td>June 22, 2016</td></tr>
      <!-- <tr><td>Papers available online</td><td>TBA</td></tr> -->
    </table>

<h3>Tuning Task Overview</h3>

    <p>

The WMT16 tuning task is similar to <a href="http://www.statmt.org/wmt15/tuning-task/">the last year tuning task</a>. We provide the participants with a complete
SMT model for English-to-Czech and
Czech-to-English translation (i.e. one
<code>moses.ini</code>
file with all the model
files for each translation direction) and a devset. A designated Moses github revision
will be used to run this model.
</p>

<p>
The participants are expected to incorporate their evaluation metric into
the moses scorer, apply whichever moses optimizer they like or use any other tuning tricks to come up
with their weight settings.
</p>

<p>
A submission to tuning task consists of an updated version of the
<code>moses.ini</code>
file, an optional weights file for sparse features (and your outputs on the official test set as an optional
sanity check).
</p>

<p>
We will run the designated moses revision using your
<code>moses.ini</code>
file to
obtain your MT outputs. (Note that the evaluation metric or tricks you used in the tuning are not needed and not used for the run.) The outputs will be manually ranked using the same
scheme as the main translation task.
</p>

<H3>Other Requirements</H3>

<p>
For each run submitted to the tuning task, the team promises to join the
WMT manual evaluation and annotate at least 100 HITs (ie. 300 5-way
comparisons). This contribution to the manual evaluation can be done in
whichever language
pair you can evaluate and is needed most.
</p>

<!--<p>No registration is needed for the participation in the tuning task, unless you would like to make use of our manual judgements of Czech, see <a href="#maneval">Complimentary Manual Evaluation</a> below.</p>-->

<p>You are invited to submit a short paper (4 to 6 pages) describing your
tuning technique. You are not required to submit a paper if you do
not want to. If you don't, we ask that you give an appropriate description (a few paragraphs) or an appropriate reference
describing your method to include or cite in the overview paper.</p>


<h3>The System to Tune</h3>

<p>
	You can download the models to tune from the following locations:
</p>
<div style="border: 1px solid #CCC; padding: 10px; display: inline-block">
<p>
	<b>English -> Czech</b>
	<br>
	<a href="https://lindat.mff.cuni.cz/repository/xmlui/handle/11372/LRT-1672">https://lindat.mff.cuni.cz/repository/xmlui/handle/11372/LRT-1672</a>
</p>
<p>
	<b>Czech -> English</b>
	<br>
	<a href="https://lindat.mff.cuni.cz/repository/xmlui/handle/11372/LRT-1671">https://lindat.mff.cuni.cz/repository/xmlui/handle/11372/LRT-1671</a>
</p>
</div>

<p>To run your optimized configurations, we will use Moses GitHub revision <a href="https://github.com/moses-smt/mosesdecoder/tree/2d6f6164801d6b61d96b7565ea2f5bc823092025">2d6f616</a> unless we run into some unexpected bug.</p>

<p>Details you may want to compare with your setup:</p>

<p>
<table border=1 cellspacing=0>
<tr>
<td></td>
<td></td>
<th>English -> Czech</th>
<th>Czech -> English</th>
</tr>
<tr><td colspan="4"/></tr>
<tr>
<th>Tuning set (newstest2015)</th>
<td>source</td>
<td><a href="newstest2015.tok.en.gz">newstest2015.tok.en.gz</a></td>
<td><a href="newstest2015.tok.cs.gz">newstest2015.tok.cs.gz</a></td>
</tr>
<tr>
<td align=center>(prepared as the models)</td>
<td>reference</td>
<td><a href="newstest2015.tok.cs.gz">newstest2015.tok.cs.gz</a></td>
<td><a href="newstest2015.tok.en.gz">newstest2015.tok.en.gz</a></td>
</tr>

<tr><td colspan="4"/></tr>
<tr>
<th>Sanity Check set (newstest2014)</th>
<td>source</td>
<td><a href="newstest2014.tok.en.gz">newstest2014.tok.en.gz</a></td>
<td><a href="newstest2014.tok.cs.gz">newstest2014.tok.cs.gz</a></td>
</tr>
<tr>
<td align=center>(prepared as the models)</td>
<td>reference</td>
<td><a href="newstest2014.tok.cs.gz">newstest2014.tok.cs.gz</a></td>
<td><a href="newstest2014.tok.en.gz">newstest2014.tok.en.gz</a></td>
</tr>
<tr>
<td></td>
<td>BLEU</td>
<!-- <td colspan=2 align=center>BLEU of our baseline tuning for reference</td> -->
<td>22.26</td>
<td>30.40</td>
</tr>
</table></p>

<p>The BLEU score reported on the Sanity Check set is based on the lowercased tokenized form.</p>


<h4>Description of the Models</h4>
<p>
<a href="http://ufal.mff.cuni.cz/czeng/czeng16pre">CzEng 1.6pre</a> corpus is used for the training of the translation models. The data is tokenized (using Moses tokenizer), lowercased and sentences longer than 60 words and shorter than 4 words are removed before training. Alignment is done using <a href="https://github.com/clab/fast_align">fast_align</a> and the standard Moses pipeline is used for training.
</p>

<p>
You are supposed to optimize the weights for these standard dense features: word penalty feature, phrase penalty feature, 4 features for a translation table (inverse phrase translation probability, inverse lexical weighting, direct phrase translation probability, direct lexical weighting), 2 features for 2 language models, distortion feature for distance-based reordering model, 6 features for each reordering model (bidirectional features for monotone, swap and discontinuous phrase translation probability).
</p>

<p>You may or may not want to add sparse features, see below.</p>


<!--
<table border='1'>
  <tr num='1'>
    <th num='1'>English-&gt;Czech</th>
    <th num='2'>Czech-&gt;English</th>
  </tr>
  <tr num='2'>
    <td num='1'><a href="en2cs-moses.ini.txt">moses.ini preview</a></td>
    <td num='2'><a href="cs2en-moses.ini.txt">moses.ini preview</a></td>
  </tr>
  <tr num='3'>
    <td num='1'><a href="en2cs_model.tgz">en2cs_model.tgz</a> (1.2GB)</td>
    <td num='2'><a href="cs2en_model.tgz">cs2en_model.tgz</a> (1.2GB)</td>
  </tr>
  <tr>
  <td colspan="2" align="center"><a href="tuning-task-dev-v2.tgz">Devset</a> (newstest2014 from translation task)
  </td>
  </tr>
  <tr>
  <th colspan="2" align="center">Original Corpora, Alignments (optional)</th>
  </tr>
  <tr>
  </tr>
  <td><a href="en2cs_original_data.tgz">en2cs_original_data.tgz</a></td>
  <td><a href="cs2en_original_data.tgz">cs2en_original_data.tgz</a></td>
</table>

<p>The models are prepared for <b>lowercase</b> input tokenized with the
<b>standard Moses tokenizer</b>
(<code>moses/scripts/tokenizer/tokenizer.perl</code>).</p>

<p>For completeness and training of some of the standard sparse features, we also provide the full corpora and alignments.</p>


<p>When evaluating your submission, we will use 
<b>Moses Release 3.0</b>, i.e. the 
github commit <a href="https://github.com/moses-smt/mosesdecoder/tree/5244a7b6075cc7b292e475c43d23c68797e8e9c0">5244a7b607</a>. This can be obtained also as pre-compiled binaries on the <a href="http://www.statmt.org/moses/?n=Moses.Releases">Moses Releases page</a>.</p>

<p>
Note that we plan to ignore any subsequent commits to the RELEASE-3.0 branch (unless prohibitive bugs are spotted). So to obtain the right sources, use:

<pre>
git clone https://github.com/moses-smt/mosesdecoder.git moses
cd moses
git checkout 5244a7b607 -b tuning-task-2016
## and *NOT*: git checkout RELEASE-3.0, which could be a newer version
</pre>
</p>

<p>Prior to manual evaluation, we will run only the Moses standard
detokenizer (<code>moses/scripts/tokenizer/detokenizer.perl</code>), upcasing
sentence beginnings. This will result in names not uppercased but in less
random effects due to the recaser. Talk to us if you think this is a bad
decision.</p>
-->


<h3>Tuning Task Tracks</h3>

<p>There are two tracks of the tuning task:

<ul>
<li>
<b>
Constrained:
</b>
You may use only the official WMT16 dev set (i.e. WMT15 test set) to tune the system.</li>
<li>
<b>
Unconstrained:
</b>
You may include any other data for the tuning, for instance older WMT test sets, additional reference translations etc.</li>
</ul>
</p>

<p>When submitting your <code>moses.ini</code>, please indicate, if your
submission is constrained or non-constrained.</p>

<p>You are allowed to modify the <code>moses.ini</code> in any way. You may
delete or add features (but you cannot supply additional model files). You may
also change the search algorithm or increase whatever limits, under the
reasonable assumption that we will be able to actually run the translation with
these settings on our machines.</p>

<p>Based on the changes you make in the <code>moses.ini</code>, we will mark your submission with these flags (within both tracks):

<ul>
<li>
<b>Basic:</b> No sparse features added, no custom settings or limits.
</li>
<li>
<b>Sparse:</b> Some sparse features added, no custom settings or limits.
</li>
<li>
<b>Customized Basic:</b> Other changes to the configuration made but no sparse features added.
</li>
<li>
<b>Customized Sparse:</b> Other changes to the configuration made, including some sparse features.
</li>
</ul>

</p>

<h4>How to add Sparse Features</h4>

<p>
Please follow
<a href=http://www.statmt.org/moses/?n=Moses.SparseFeatures>Moses documentation</a> for instructions on adding sparse features to your
<code>moses.ini</code>. If you add
sparse features then you will probably have to use kbmira or PRO for the tuning
of their weights.
</p>

<p>
For example, you can add sparse features for target word insertion by adding the following line to your moses.ini:
<br/>
<pre>[feature]
SourceWordDeletionFeature factor=0
</pre>
</p>

<p>
When you use sparse features, the weights are not stored in
<code>moses.ini</code> but in an
additional weights file. Make sure to include this weights file with your
submission of <code>moses.ini</code>.
</p>


<a name="maneval"></a>
<h3>Complimentary Manual Evaluation of Translations into Czech</h3>

<p>
To allow a broader participation in the English-to-Czech direction, each
registered participant of the tuning task will be given a 'credit'
of manual pairwise sentence comparisons by our Czech native speakers. The
exact number of judgments we can provide will be determined from the number
of registered participants, but we expect no less than a few hundred sentence pair comparisons.
Obviously, manual judging takes time and there can be a peak of demand as
the submission deadline approaches, so remember to get in touch early.
</p>

<p>
To register for this English-to-Czech complimentary  manual pre-evaluation,
please send an e-mail to
  <a href="mailto:wmt-tuning-submissions@googlegroups.com">wmt-tuning-submissions@googlegroups.com</a>.
</p>

<h4>Submitting Sentence Pairs for Czech Manual Evaluation</h4>

<p>To make use of some of your 'credit', simply send the following plain text files to 
  <a href="mailto:wmt-tuning-submissions@googlegroups.com">wmt-tuning-submissions@googlegroups.com</a>:

  <ul>
  <li>The source English sentence.</li>
  <li>The reference translation (if available).</li>
  <li>System A output</li>
  <li>System B output</li>
  </ul>

  Each sentence should be on a separate line, so all the three or four files must have exactly the same number of lines.
</p>

<p>
Our annotators will see the source, optionally the reference, and the two outputs. The outputs will be shuffled so that the system cannot be determined from the order of the hypotheses. The order of the sentences will not be shuffled, so do this yourself if you want to.
</p>

<p>
For each sentence, the annotator will mark one of the following:
<ul>
<li>Exactly one candidate translation as being the better one.</li>
<li>Both candidates as being equally good, acceptable translations.</li>
<li>Both candidates as being equally bad, inacceptable translations.</li>
</ul>
</p>

<H4>How to submit</H4>
<p>
Submissions should be sent as an e-mail to <a href="wmt-tuning-submissions@googlegroups.com">wmt-tuning-submissions@googlegroups.com</a>.
</p>

<p>In case the above e-mail doesn't work for you (Google seems to prevent non-member postings despite we set it so), please contact us directly.</p>


<h3>Tuning Task Organizers</h3>
Milo&#353; Stanojevi&#263; (University of Amsterdam, ILLC)<br>
Bushra Jawaid (University of Amsterdam, ILLC)<br>
Amir Kamran (University of Amsterdam, ILLC)<br>
Ond&#345;ej Bojar (Charles University in Prague)<br>


<h3>Acknowledgement</h3>
<p>
Supported by the European Commision under the
<a href="http://www.qt21.eu/"><img src="qt21-quality-translation-cropped.png" border=0 width=105 height=45 alt="QT 21"></a> project (grant number 645452) <p>

  </body>
</html>
